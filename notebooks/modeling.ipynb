{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a45691-7e06-49c2-a7c0-7997d9741997",
   "metadata": {},
   "source": [
    "# Hepatitis Challenge\n",
    "\n",
    "## Plan\n",
    "### 1. Clean dataset\n",
    "+ Categoricals\n",
    "    + SEX -> homogenize values to M or F\n",
    "    + Missing values '?' on multiple columns\n",
    "        + Drop column\n",
    "        + Drop row\n",
    "        + Fill with mode\n",
    "        + Impute with KNN\n",
    "+ Numericals\n",
    "    + Missing values '?' -> Impute with KNN\n",
    "### 2. Dataset Split\n",
    "+ X/y split\n",
    "+ Train / Test Split\n",
    "### 3. Scaling with Standard Scaler\n",
    "### 4. Fix Class Imbalance\n",
    "+ Upsampling\n",
    "+ Downsampling\n",
    "+ SMOTE\n",
    "+ Tomek\n",
    "### 5. Feature selection?\n",
    "### 6. Model selection\n",
    "+ Random Forest\n",
    "+ Logistic Regression\n",
    "+ KNN\n",
    "### 7. Model evaluation\n",
    "+ Optimize -> Kappa\n",
    "### 8. Model tuning\n",
    "+ RandomSearchCV + GridSearchCV\n",
    "\n",
    "\n",
    "### Submission variations:\n",
    "1. Dataset 1\n",
    "2. Dataset 2 -> Not including 'PRO TIME'\n",
    "3. Dataset 3 -> Tomek vs. SMOTE balancing methods?\n",
    "4. ?\n",
    "5. ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb610b65-5de3-4202-9964-ca7bfaf3cfdb",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d124bf-6cf0-4823-9759-c6bd5d5e917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5793d-5adb-42f7-b37c-95193dda35c3",
   "metadata": {},
   "source": [
    "# Load Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "445061a3-27b1-444e-ba5a-5cdb3af10520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ANTIVIRALS</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>MALAISE</th>\n",
       "      <th>ANOREXIA</th>\n",
       "      <th>LIVER BIG</th>\n",
       "      <th>LIVER FIRM</th>\n",
       "      <th>BILIRUBIN</th>\n",
       "      <th>ALK PHOSPHATE</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>ALBUMIN</th>\n",
       "      <th>PROTIME</th>\n",
       "      <th>HISTOLOGY</th>\n",
       "      <th>SPLEEN PALPABLE</th>\n",
       "      <th>SPIDERS</th>\n",
       "      <th>ASCITES</th>\n",
       "      <th>VARICES</th>\n",
       "      <th>STEROID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>62.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>181.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  SEX  ANTIVIRALS  FATIGUE  MALAISE  ANOREXIA  LIVER BIG  LIVER FIRM  \\\n",
       "0  48.0  1.0         2.0      1.0      1.0       2.0        2.0         1.0   \n",
       "1  51.0  1.0         2.0      1.0      2.0       2.0        2.0         1.0   \n",
       "2  40.0  1.0         2.0      1.0      2.0       2.0        2.0         1.0   \n",
       "3  25.0  1.0         2.0      1.0      2.0       2.0        1.0         1.0   \n",
       "4  34.0  1.0         2.0      1.0      2.0       2.0        1.0         1.0   \n",
       "\n",
       "   BILIRUBIN  ALK PHOSPHATE   SGOT  ALBUMIN  PROTIME  HISTOLOGY  \\\n",
       "0        4.8          123.0  157.0      2.7     31.0        2.0   \n",
       "1        1.0           79.6   20.0      3.0     63.0        2.0   \n",
       "2        0.6           62.0  166.0      4.0     63.0        1.0   \n",
       "3        1.3          181.0  181.0      4.5     57.0        2.0   \n",
       "4        1.0           72.0   46.0      4.4     57.0        1.0   \n",
       "\n",
       "   SPLEEN PALPABLE  SPIDERS  ASCITES  VARICES  STEROID  Class  \n",
       "0              2.0      1.0      1.0      1.0      1.0    1.0  \n",
       "1              1.0      1.0      2.0      1.0      2.0    2.0  \n",
       "2              2.0      2.0      2.0      2.0      1.0    2.0  \n",
       "3              1.0      1.0      1.0      1.0      2.0    2.0  \n",
       "4              2.0      1.0      2.0      2.0      1.0    2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/clean_data/train_clean.csv')\n",
    "df_no_class = pd.read_csv('../data/clean_data/test_no_class_clean.csv')\n",
    "\n",
    "# Show data & shape\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3dfc500-1eb1-4f9d-9443-2b6617b39673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ANTIVIRALS</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>MALAISE</th>\n",
       "      <th>ANOREXIA</th>\n",
       "      <th>LIVER BIG</th>\n",
       "      <th>LIVER FIRM</th>\n",
       "      <th>BILIRUBIN</th>\n",
       "      <th>ALK PHOSPHATE</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>ALBUMIN</th>\n",
       "      <th>PROTIME</th>\n",
       "      <th>HISTOLOGY</th>\n",
       "      <th>SPLEEN PALPABLE</th>\n",
       "      <th>SPIDERS</th>\n",
       "      <th>ASCITES</th>\n",
       "      <th>VARICES</th>\n",
       "      <th>STEROID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>62.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>181.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  SEX  ANTIVIRALS  FATIGUE  MALAISE  ANOREXIA  LIVER BIG  LIVER FIRM  \\\n",
       "0  48.0  1.0         2.0      1.0      1.0       2.0        2.0         1.0   \n",
       "1  51.0  1.0         2.0      1.0      2.0       2.0        2.0         1.0   \n",
       "2  40.0  1.0         2.0      1.0      2.0       2.0        2.0         1.0   \n",
       "3  25.0  1.0         2.0      1.0      2.0       2.0        1.0         1.0   \n",
       "4  34.0  1.0         2.0      1.0      2.0       2.0        1.0         1.0   \n",
       "\n",
       "   BILIRUBIN  ALK PHOSPHATE   SGOT  ALBUMIN  PROTIME  HISTOLOGY  \\\n",
       "0        4.8          123.0  157.0      2.7     31.0        2.0   \n",
       "1        1.0           79.6   20.0      3.0     63.0        2.0   \n",
       "2        0.6           62.0  166.0      4.0     63.0        1.0   \n",
       "3        1.3          181.0  181.0      4.5     57.0        2.0   \n",
       "4        1.0           72.0   46.0      4.4     57.0        1.0   \n",
       "\n",
       "   SPLEEN PALPABLE  SPIDERS  ASCITES  VARICES  STEROID  Class  \n",
       "0              2.0      1.0      1.0      1.0      1.0    1.0  \n",
       "1              1.0      1.0      2.0      1.0      2.0    2.0  \n",
       "2              2.0      2.0      2.0      2.0      1.0    2.0  \n",
       "3              1.0      1.0      1.0      1.0      2.0    2.0  \n",
       "4              2.0      1.0      2.0      2.0      1.0    2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbd40f-ebc0-40b7-9c2e-21234eada9b5",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936725a0-8f61-44d6-9484-fd55297523a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show value counts for each column\n",
    "#for col in df.columns:\n",
    "#    display(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927d47e-ef2f-4faf-abcf-c09cf136be7e",
   "metadata": {},
   "source": [
    "# Split Features / Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33e26da-2beb-4c1b-b8ec-8de05267d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features from the target\n",
    "y = df['Class']\n",
    "X = df.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c666559-6f93-49e8-a6a1-db17ba9bc81d",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cdb0e0a-0d85-4c02-b04a-0e39087c4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908563ef-00b9-49a3-ab4b-bba5a0a46b8b",
   "metadata": {},
   "source": [
    "# Scale Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17140e30-402f-4d2f-a4bd-14ec4b1782c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler with TRAIN data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale X_train_num_transformed with fitted scaler. Output is a np.array.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Add columns to np.array to create a DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, \n",
    "                                 columns=X_train.columns, \n",
    "                                 index=X_train.index)\n",
    "\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, \n",
    "                                columns=X_test.columns,\n",
    "                                index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc9d6e-64ad-4acc-a3c5-473fe4ea4314",
   "metadata": {},
   "source": [
    "# Balance Target Column\n",
    "\n",
    "Four possible methods:\n",
    "+ Upsampling minority class\n",
    "+ Downsampling majority class\n",
    "+ SMOTE\n",
    "+ TOMEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8529b903-ce49-4ea4-b6ac-c664627211c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class imbalance ratio is: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Show imablance ratio\n",
    "count_classes = df['Class'].value_counts()\n",
    "print(\"The class imbalance ratio is: {:.2f}\".format((count_classes[2]-count_classes[1])/(count_classes[2]+count_classes[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4cd4c9f-e48e-487f-a46b-422fe4b7c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class imbalance ratio is: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Upsampling minority class\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_over, y_train_over = ros.fit_resample(X_train_scaled_df, y_train)\n",
    "\n",
    "count_classes = y_train_over.value_counts()\n",
    "\n",
    "print(\"The class imbalance ratio is: {:.2f}\".format((count_classes[2]-count_classes[1])/(count_classes[2]+count_classes[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca5800f-5057-4831-8d9f-27a16ebd36f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class imbalance ratio is: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Downsampling majority class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train_scaled_df, y_train)\n",
    "\n",
    "count_classes = y_train_over.value_counts()\n",
    "\n",
    "print(\"The class imbalance ratio is: {:.2f}\".format((count_classes[2]-count_classes[1])/(count_classes[2]+count_classes[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad3e50c-8091-4bb6-8725-daf9d63d381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class imbalance ratio is: 0.00\n"
     ]
    }
   ],
   "source": [
    "# SMOTE\n",
    "sm = SMOTE(random_state=100,k_neighbors=3)\n",
    "\n",
    "X_train_SMOTE,y_train_SMOTE = sm.fit_resample(X_train_scaled_df, y_train)\n",
    "\n",
    "count_classes = y_train_over.value_counts()\n",
    "\n",
    "print(\"The class imbalance ratio is: {:.2f}\".format((count_classes[2]-count_classes[1])/(count_classes[2]+count_classes[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6948a4-cf76-45ad-bdc3-d8e3f4e4b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class imbalance ratio is: 0.00\n"
     ]
    }
   ],
   "source": [
    "# TomekLinks\n",
    "tl = TomekLinks()\n",
    "\n",
    "X_train_tl, y_train_tl = tl.fit_resample(X_train_scaled_df, y_train)\n",
    "\n",
    "count_classes = y_train_over.value_counts()\n",
    "\n",
    "print(\"The class imbalance ratio is: {:.2f}\".format((count_classes[2]-count_classes[1])/(count_classes[2]+count_classes[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1cdd19f-cab8-411d-8a68-c28d33682418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select balancing method\n",
    "#X_train_balanced = X_train_SMOTE\n",
    "#y_train_balanced = y_train_SMOTE\n",
    "\n",
    "#X_train_balanced = X_train_tl\n",
    "#y_train_balanced = y_train_tl\n",
    "\n",
    "#X_train_balanced = X_train_under\n",
    "#y_train_balanced = y_train_under\n",
    "\n",
    "X_train_balanced = X_train_over \n",
    "y_train_balanced = y_train_over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98a9ff-e330-42a0-9043-2e5bede0c5a9",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f0385d4-0b01-4cb0-a645-eb7362b32a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': 0.9568840579710145, 'Random Forest Classifier': 0.9565217391304348, 'KNN': 0.8967391304347826}\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "model1 = LogisticRegression()\n",
    "model2 = RandomForestClassifier()\n",
    "model3 = KNeighborsClassifier()\n",
    "\n",
    "model_pipeline = [model1, model2, model3]\n",
    "model_names = ['Logistic Regression', 'Random Forest Classifier', 'KNN']\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for model, model_name in zip(model_pipeline, model_names):\n",
    "    mean_score = np.mean(cross_val_score(model, X_train_balanced, y_train_balanced, cv=5))\n",
    "    scores[model_name] = mean_score\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04fe6e-3f61-4b28-9b3e-50aeff4fc411",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0ead70-1ad8-4dc2-855c-9adc69da24da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters:\n",
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 175}\n",
      "Best Model Kappa Score on Test Data: 0.5201238390092879\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(20, 200, 10), # (50, 200, 10)\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': np.arange(5, 15), # np.arange(5, 15)\n",
    "    'min_samples_split': np.arange(2, 11), # np.arange(2, 11)\n",
    "    'min_samples_leaf': np.arange(1, 11), # np.arange(1, 11)\n",
    "    'max_features': ['sqrt', 'log2', None], #  ['sqrt', 'log2', None]\n",
    "    'bootstrap': [True, False] # [True, False]\n",
    "}\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define Kappa score as the scoring metric\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "# Create RandomizedSearchCV object with Kappa score as the scoring metric\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=5,\n",
    "                                   scoring=kappa_scorer, random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "best_params_from_random_search = random_search.best_params_\n",
    "\n",
    "# Define a smaller range around the best parameters for GridSearchCV\n",
    "param_grid_for_grid_search = {\n",
    "    'n_estimators': np.arange(best_params_from_random_search['n_estimators'] - 20,\n",
    "                               best_params_from_random_search['n_estimators'] + 20, 5),\n",
    "    'criterion': [best_params_from_random_search['criterion']],\n",
    "    'max_depth': np.arange(best_params_from_random_search['max_depth'] - 2,\n",
    "                           best_params_from_random_search['max_depth'] + 5),\n",
    "    'min_samples_split': np.arange(best_params_from_random_search['min_samples_split'],#  - 1,\n",
    "                                   best_params_from_random_search['min_samples_split'] + 5),\n",
    "    'min_samples_leaf': np.arange(best_params_from_random_search['min_samples_leaf'], # - 1,\n",
    "                                  best_params_from_random_search['min_samples_leaf'] + 5),\n",
    "    'max_features': [best_params_from_random_search['max_features']],\n",
    "    'bootstrap': [best_params_from_random_search['bootstrap']]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object with Kappa score as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_for_grid_search, cv=5,\n",
    "                           scoring=kappa_scorer, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on the training data\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = best_model.predict(X_test_scaled_df)\n",
    "kappa_score_test = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Model Parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best Model Kappa Score on Test Data:\", kappa_score_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a09e08-85e1-4466-b58c-7c91d1dde12b",
   "metadata": {},
   "source": [
    "### Feature Importance Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "450a2144-bf83-400a-af21-d40dc2b8cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Rankings:\n",
      "1. Feature ALBUMIN: Importance = 0.24349968623436136\n",
      "2. Feature BILIRUBIN: Importance = 0.22957043294851773\n",
      "3. Feature PROTIME: Importance = 0.0747714182757526\n",
      "4. Feature ASCITES: Importance = 0.06401213926207194\n",
      "5. Feature ALK PHOSPHATE: Importance = 0.0599576067084904\n",
      "6. Feature AGE: Importance = 0.0552128641895017\n",
      "7. Feature FATIGUE: Importance = 0.050281683848777944\n",
      "8. Feature MALAISE: Importance = 0.04761205294715983\n",
      "9. Feature HISTOLOGY: Importance = 0.046162763865283396\n",
      "10. Feature SGOT: Importance = 0.03711546166618276\n",
      "11. Feature SPIDERS: Importance = 0.03243609897104653\n",
      "12. Feature SPLEEN PALPABLE: Importance = 0.017302966628040855\n",
      "13. Feature SEX: Importance = 0.012034496628982152\n",
      "14. Feature ANOREXIA: Importance = 0.006631807522857179\n",
      "15. Feature STEROID: Importance = 0.006443107804144109\n",
      "16. Feature LIVER BIG: Importance = 0.005089436174430484\n",
      "17. Feature ANTIVIRALS: Importance = 0.004406138580653675\n",
      "18. Feature LIVER FIRM: Importance = 0.0039397958165910026\n",
      "19. Feature VARICES: Importance = 0.0035200419271543357\n"
     ]
    }
   ],
   "source": [
    "# Get the feature importances\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Sort feature importances and corresponding feature names together\n",
    "feature_importance_names = list(zip(importances, X_train_balanced.columns))\n",
    "feature_importance_names.sort(reverse=True)\n",
    "\n",
    "# Print the feature rankings\n",
    "print(\"Feature Rankings:\")\n",
    "for i, (importance, feature_name) in enumerate(feature_importance_names):\n",
    "    print(f\"{i + 1}. Feature {feature_name}: Importance = {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9965a3de-fbf5-4849-8897-c9ab85a8fefc",
   "metadata": {},
   "source": [
    "# Transform and Predict Submission Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6dc8bb-89c4-4b5b-8c39-be88375b8fc4",
   "metadata": {},
   "source": [
    "## Scale Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2056ad00-ea28-4dd0-987a-b743566c4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler with TRAIN data\n",
    "scaler.fit(df_no_class)\n",
    "\n",
    "# Scale X_train_num_transformed with fitted scaler. Output is a np.array.\n",
    "df_no_class_scaled = scaler.transform(df_no_class)\n",
    "\n",
    "# Add columns to np.array to create a DataFrame\n",
    "df_no_class_scaled_df = pd.DataFrame(df_no_class_scaled, \n",
    "                                     columns=df_no_class.columns, \n",
    "                                     index=df_no_class.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c905e-1075-4053-bfc0-bc19f618441f",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9d52721-d2ab-4150-b090-a05fe92a270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_no_class = best_model.predict(df_no_class_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9e90546-4c47-4be0-ac81-47856705919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into DataFrame\n",
    "y_pred_no_class_df = pd.DataFrame(y_pred_no_class, columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b3929fb-b11a-4b89-aea9-05fd183f7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 1,2 with DIE, LIVE\n",
    "y_pred_no_class_df['Class'].replace({1:'DIE', 2:'LIVE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f1ddb7-6696-4c6b-acf5-3e9ab092d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "y_pred_no_class_df.to_csv('../data/submission_data/group_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828270a6-6310-488d-b17e-3ddd7b4f3c25",
   "metadata": {},
   "source": [
    "### Check Submission Kappa with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f09045c-db66-4fe9-aae9-8835a8c61144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6310904872389791"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best result\n",
    "test_df = pd.read_csv('../data/raw_data/test.csv')\n",
    "\n",
    "y_no_class_test = test_df['Class']\n",
    "y_pred_no_class = y_pred_no_class_df['Class']\n",
    "\n",
    "final_kappa = cohen_kappa_score(y_no_class_test, y_pred_no_class)\n",
    "final_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aee8032-93b0-43f9-80a0-e4c99a9d5a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42640692640692635"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submission 1\n",
    "sub_1_df = pd.read_csv('../data/submission_data/group_2_sub_1.csv')\n",
    "y_pred_no_class = sub_1_df['Class']\n",
    "\n",
    "final_kappa = cohen_kappa_score(y_no_class_test, y_pred_no_class)\n",
    "final_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1104c8e-1a54-4f86-a33c-32e0b6ad2487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42599277978339356"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submission 2\n",
    "sub_1_df = pd.read_csv('../data/submission_data/group_2_sub_2.csv')\n",
    "y_pred_no_class = sub_1_df['Class']\n",
    "\n",
    "final_kappa = cohen_kappa_score(y_no_class_test, y_pred_no_class)\n",
    "final_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4ebeab2-862b-4d81-911c-9369b808b35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.462474645030426"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submission 3\n",
    "sub_1_df = pd.read_csv('../data/submission_data/group_2_sub_3.csv')\n",
    "y_pred_no_class = sub_1_df['Class']\n",
    "\n",
    "final_kappa = cohen_kappa_score(y_no_class_test, y_pred_no_class)\n",
    "final_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fe8de-8d98-45e0-969c-900e902eaf10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
