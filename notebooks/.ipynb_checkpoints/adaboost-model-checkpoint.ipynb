{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaca70f-d7ce-4af5-a53b-851d1bdebf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(20, 200, 10), # (50, 200, 10)\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': np.arange(5, 15), # np.arange(5, 15)\n",
    "    'min_samples_split': np.arange(2, 11), # np.arange(2, 11)\n",
    "    'min_samples_leaf': np.arange(1, 11), # np.arange(1, 11)\n",
    "    'max_features': ['sqrt', 'log2', None], #  ['sqrt', 'log2', None]\n",
    "    'bootstrap': [True, False] # [True, False]\n",
    "}\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define Kappa score as the scoring metric\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "# Create RandomizedSearchCV object with Kappa score as the scoring metric\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=5,\n",
    "                                   scoring=kappa_scorer, random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "best_params_from_random_search = random_search.best_params_\n",
    "\n",
    "# Define a smaller range around the best parameters for GridSearchCV\n",
    "param_grid_for_grid_search = {\n",
    "    'n_estimators': np.arange(best_params_from_random_search['n_estimators'] - 20,\n",
    "                               best_params_from_random_search['n_estimators'] + 20, 5),\n",
    "    'criterion': [best_params_from_random_search['criterion']],\n",
    "    'max_depth': np.arange(best_params_from_random_search['max_depth'] - 2,\n",
    "                           best_params_from_random_search['max_depth'] + 5),\n",
    "    'min_samples_split': np.arange(best_params_from_random_search['min_samples_split'],#  - 1,\n",
    "                                   best_params_from_random_search['min_samples_split'] + 5),\n",
    "    'min_samples_leaf': np.arange(best_params_from_random_search['min_samples_leaf'], # - 1,\n",
    "                                  best_params_from_random_search['min_samples_leaf'] + 5),\n",
    "    'max_features': [best_params_from_random_search['max_features']],\n",
    "    'bootstrap': [best_params_from_random_search['bootstrap']]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object with Kappa score as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_for_grid_search, cv=5,\n",
    "                           scoring=kappa_scorer, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on the training data\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = best_rf_model.predict(X_test_transformed_df)\n",
    "kappa_score_test = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Model Parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best Model Kappa Score on Test Data:\", kappa_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fad39a-59cb-4d5a-9404-c5b3ba1d919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Parameter grid for AdaBoostClassifier\n",
    "adaboost_param_grid = {\n",
    "    'n_estimators': np.arange(50, 200, 10),\n",
    "    'learning_rate': np.linspace(0.1, 2, 20),\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "# Define the class weights\n",
    "class_weights = {1: 5, 2: 1}  # Class \"2\" is the minority class\n",
    "\n",
    "# Create an AdaBoost classifier with a decision tree as the base estimator\n",
    "adaboost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1, class_weight=class_weights), n_estimators=100)\n",
    "\n",
    "# Define Kappa score as the scoring metric\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "# Create RandomizedSearchCV object for AdaBoosting\n",
    "random_search_adaboost = RandomizedSearchCV(estimator=adaboost, param_distributions=adaboost_param_grid,\n",
    "                                            n_iter=100, cv=5, scoring=kappa_scorer, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training data\n",
    "random_search_adaboost.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "best_params_from_random_search_adaboost = random_search_adaboost.best_params_\n",
    "\n",
    "# Define a smaller range around the best parameters for GridSearchCV\n",
    "param_grid_for_grid_search_adaboost = {\n",
    "    'n_estimators': np.arange(best_params_from_random_search_adaboost['n_estimators'] - 20,\n",
    "                               best_params_from_random_search_adaboost['n_estimators'] + 20, 5),\n",
    "    'learning_rate': np.linspace(best_params_from_random_search_adaboost['learning_rate'] ,\n",
    "                                 best_params_from_random_search_adaboost['learning_rate'] + 0.5, 10),\n",
    "    'algorithm': [best_params_from_random_search_adaboost['algorithm']]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object for AdaBoosting\n",
    "grid_search_adaboost = GridSearchCV(estimator=adaboost, param_grid=param_grid_for_grid_search_adaboost,\n",
    "                                    cv=5, scoring=kappa_scorer, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on the training data\n",
    "grid_search_adaboost.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_adaboost_model = grid_search_adaboost.best_estimator_\n",
    "best_params_adaboost = grid_search_adaboost.best_params_\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred_adaboost = best_adaboost_model.predict(X_test_scaled_df)\n",
    "kappa_score_test_adaboost = cohen_kappa_score(y_test, y_pred_adaboost)\n",
    "\n",
    "print(\"Best AdaBoost Model Parameters:\")\n",
    "print(best_params_adaboost)\n",
    "print(\"Best AdaBoost Model Kappa Score on Test Data:\", kappa_score_test_adaboost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
